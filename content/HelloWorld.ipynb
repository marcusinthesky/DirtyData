{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Hello](https://media1.tenor.com/images/469f17daad56085938aafe44c44d31fd/tenor.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hello.  I'm Marcus, and I have a data problem. üç∑ DirtyData is blog about bad data and good Data Science.  I don't know eveything but hopefully we will learnt together. üìì Over the next few posts we will play with categorical data- the sparser the better- we will look at how to build data pipelines and cool techniques in exploring them. ü§ì I am the worst spelling and grammar-checker, so I will appologize for the fact that what I write is unreadable.  As someone living in South Africa and interested in African data problems, we will try chat and get input from local Data Scientists and researchers on what they are learning and what is keeping them exciting.  üåî"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I thought it may be fun, as an introduction and for you to get to know me, to explore some of my personal data and thanks to GDPR and Facebook's repent I know own my data and can explore it with you with some fun graphs and visuals.  Hurray! üí• Check out how to [download](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=4&cad=rja&uact=8&ved=0ahUKEwiMmYj4zYfcAhXUa8AKHRnSBXMQFgg6MAM&url=https%3A%2F%2Fwww.wired.com%2Fstory%2Fdownload-facebook-data-how-to-read%2F&usg=AOvVaw30_I7goGnKq1ltdH4vxU8D) your own.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to appologie in advanced for importing all these libraries.  üìö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models.deprecated.old_saveload import SaveLoad\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here are my all the posts I have been tagged in.  There are only around 800, as I am not that popular. üò≠ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(\".\",\"Datasets\",\"facebook_posts\",\"other_people's_posts_to_your_timeline.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = pd.read_json(path, orient='list')\n",
    "posts = pd.io.json.json_normalize(json_file.wall_posts_sent_to_you)\n",
    "\n",
    "posts.data = posts.data.astype(str).apply(lambda x: x[11:-3])\n",
    "posts.timestamp = pd.to_datetime(posts.timestamp, unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attachments</th>\n",
       "      <th>data</th>\n",
       "      <th>tags</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>May your year ahead be fuelled with energy and...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-05-15 08:52:55</td>\n",
       "      <td>Fleur Lerwill added a new photo to Marcus Gawr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Happy birthday my wonderful friend.  Have a ma...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-05-13 11:53:53</td>\n",
       "      <td>Geoff Olivier wrote on your timeline.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Happy birthday Marcus!! Hope you had a great day</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-05-13 10:18:45</td>\n",
       "      <td>Javan Moodley wrote on your timeline.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>happy birthday bud, hope it's been great!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-05-12 19:35:34</td>\n",
       "      <td>James Combrink wrote on your timeline.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Happy birthday Marcus! Hope you've had a great...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-05-12 18:14:07</td>\n",
       "      <td>Jason W Gaskell wrote on your timeline.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  attachments                                               data tags  \\\n",
       "0         NaN  May your year ahead be fuelled with energy and...  NaN   \n",
       "1         NaN  Happy birthday my wonderful friend.  Have a ma...  NaN   \n",
       "2         NaN   Happy birthday Marcus!! Hope you had a great day  NaN   \n",
       "3         NaN          happy birthday bud, hope it's been great!  NaN   \n",
       "4         NaN  Happy birthday Marcus! Hope you've had a great...  NaN   \n",
       "\n",
       "            timestamp                                              title  \n",
       "0 2018-05-15 08:52:55  Fleur Lerwill added a new photo to Marcus Gawr...  \n",
       "1 2018-05-13 11:53:53              Geoff Olivier wrote on your timeline.  \n",
       "2 2018-05-13 10:18:45              Javan Moodley wrote on your timeline.  \n",
       "3 2018-05-12 19:35:34             James Combrink wrote on your timeline.  \n",
       "4 2018-05-12 18:14:07            Jason W Gaskell wrote on your timeline.  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be using a cool technique called [Word2Vec](https://www.tensorflow.org/tutorials/word2vec) for word embeddings üî†.  I will be using a [pretrained embeddings](https://github.com/jhlau/doc2vec#pre-trained-doc2vec-models), as I have neither the time, nor money to learn my own üèã.  In order to create the document embeddings I will be using a weighting of the [term frequency‚Äìinverse document frequencies](https://en.wikipedia.org/wiki/Tf%E2%80%93idf).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_wiki = SaveLoad.load('./Models/W2V_enwiki/word2vec.bin', mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedWordVectors(TransformerMixin):\n",
    "    \"\"\"Trains Collation Model to join co-occuring works into single entities or concepts\n",
    "    \n",
    "    Libraries & Versions:\n",
    "    Python==3.6.5\n",
    "    Pandas=='0.23.1' as pd\n",
    "    nltk=='3.3'\n",
    "    numpy=='1.14.5'\n",
    "    \n",
    "    Keyword arguments:\n",
    "    X -- Pandas Series of text as strings\n",
    "    \"\"\"\n",
    "    def __init__(self, model=None):\n",
    "        self.word2vec =  model\n",
    "        self.tfidf = TfidfVectorizer(vocabulary= list(self.word2vec.vocab.keys()))\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.tfidf.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        self.weighted_docs = []\n",
    "        \n",
    "        for doc in X:\n",
    "            self.t = self.tfidf.transform([doc])\n",
    "            self.words = np.array(list(self.tfidf.vocabulary_.keys()))[self.t.nonzero()[1]]\n",
    "            self.weights = self.t[0,self.t.nonzero()[1]].todense()\n",
    "            \n",
    "            self.weighted_doc = np.empty((300,), float)\n",
    "            for word, weight in zip(self.words.tolist(), self.weights.tolist()[0]):\n",
    "                try:\n",
    "                    self.weighted_doc = self.weighted_doc + w2v_wiki[word] * weight\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "            self.weighted_docs.append(self.weighted_doc.tolist())\n",
    "                \n",
    "        return(pd.DataFrame(self.weighted_docs).fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighter = WeightedWordVectors(w2v_wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_vectors = weighter.fit_transform(posts.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_similarities = pairwise_distances(document_vectors.astype(np.float64), metric='cosine', n_jobs=-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common tool in visualizing the document vectors is using T-distributed Stochastic Neighbour Embeddings to convert the document similarities into two components which maintain the overall structure of the documents.  üå≥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_tsne = TSNE(metric=\"precomputed\")\n",
    "document_comp = document_tsne.fit_transform(document_similarities)\n",
    "\n",
    "document_comp = pd.DataFrame(document_comp, columns=['x','y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LET'S CHECK THE PLOT! üìä I've tried to make it a bit interactive so you can see the grouped posts.  ENJOY.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~marcussky/37.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py.iplot([go.Scatter(x=document_comp.x.tolist(), y=document_comp.y.tolist(),  mode = 'markers', opacity=0.5, text=posts.data.tolist())])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
